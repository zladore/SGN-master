#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import torch
import torch.optim as optim
import os
import json
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import math
import datetime
import shutil

from loader.data_loader import ParticleDataLoader
from models.model_builder import build_model
from training import train_epoch
from validation import val_epoch
from torch.optim.lr_scheduler import LambdaLR


# ===============================================================
# ğŸ”¹ å¯è§†åŒ–å‡½æ•°ï¼šç»˜åˆ¶é¢„æµ‹ vs çœŸå€¼ å¯¹æ¯”å›¾ï¼ˆå¸¦åå½’ä¸€åŒ–ï¼‰
# ===============================================================
@torch.no_grad()
def plot_predictions(model, data_loader, device, epoch, label_mean=None, label_std=None, save_dir="results"):
    model.eval()
    all_preds, all_labels = [], []

    for batch in data_loader:
        images = batch["image"].to(device)
        labels = batch["label"].to(device)

        outputs = model(images)

        preds = outputs.detach().cpu().numpy().flatten()
        trues = labels.detach().cpu().numpy().flatten()

        all_preds.extend(preds)
        all_labels.extend(trues)
        break  # åªå–ä¸€ä¸ª batch å¯è§†åŒ–

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)

    # âœ… åå½’ä¸€åŒ–ï¼ˆå¦‚æœæä¾›äº†å‡å€¼å’Œæ–¹å·®ï¼‰
    if label_mean is not None and label_std is not None:
        label_mean = np.array(label_mean)
        label_std = np.array(label_std)
        all_preds = all_preds * label_std.mean() + label_mean.mean()
        all_labels = all_labels * label_std.mean() + label_mean.mean()

    mse = np.mean((all_preds - all_labels) ** 2)
    mae = np.mean(np.abs(all_preds - all_labels))

    plt.figure(figsize=(10, 5))
    plt.plot(all_preds, label="prediction", color='royalblue', linewidth=1)
    plt.plot(all_labels, label="truth", color='orange', linewidth=1, alpha=0.8)
    plt.title(f"Epoch {epoch} | MSE={mse:.4f} | MAE={mae:.4f}")
    plt.xlabel("Sample index")
    plt.ylabel("Value")
    plt.legend()
    plt.tight_layout()

    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"pred_vs_truth_epoch_{epoch}.png")
    plt.savefig(save_path)
    plt.close()
    print(f"âœ… å·²ä¿å­˜é¢„æµ‹å¯¹æ¯”å›¾: {save_path}")


# ===============================================================
# ğŸ”¹ æ„å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
# ===============================================================
def build_scheduler(optimizer, config):
    sched_cfg = config.get("scheduler", {})
    name = sched_cfg.get("name", None)

    if name == "CosineAnnealingWarmup":
        warmup_epochs = sched_cfg.get("warmup_epochs", 10)
        max_epochs = sched_cfg.get("max_epochs", 200)
        min_lr = sched_cfg.get("min_lr", 1e-6)
        base_lr = optimizer.param_groups[0]["lr"]

        def lr_lambda(epoch):
            if epoch < warmup_epochs:
                return epoch / warmup_epochs
            else:
                cosine_decay = 0.5 * (1 + math.cos(math.pi * (epoch - warmup_epochs) /
                                                   (max_epochs - warmup_epochs)))
                return cosine_decay * (1 - min_lr / base_lr) + (min_lr / base_lr)

        scheduler = LambdaLR(optimizer, lr_lambda)
        print(f"âœ… ä½¿ç”¨ CosineAnnealingWarmup è°ƒåº¦å™¨: warmup={warmup_epochs}, total={max_epochs}")
        return scheduler

    print("âš ï¸ æœªå®šä¹‰æˆ–ä½¿ç”¨é»˜è®¤å­¦ä¹ ç‡ï¼ˆæ— è°ƒåº¦ï¼‰")
    return None


# ===============================================================
# ğŸ”¹ ä¸»å‡½æ•°
# ===============================================================
def main():
    # 1ï¸âƒ£ åŠ è½½é…ç½®æ–‡ä»¶
    config_path = "data/particle_config/particle_config.json"
    with open(config_path, 'r') as f:
        config = json.load(f)

    # ä»é…ç½®ä¸­æå–å½’ä¸€åŒ–å‚æ•°ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
    input_mean = np.array(config.get("input_mean", [0]))
    input_std = np.array(config.get("input_std", [1]))
    label_mean = np.array(config.get("label_mean", [0]))
    label_std = np.array(config.get("label_std", [1]))

    # 2ï¸âƒ£ è®¾å¤‡è®¾ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")

    # 3ï¸âƒ£ åˆ›å»ºæ•°æ®åŠ è½½å™¨
    data_module = ParticleDataLoader(config)
    train_loader, val_loader, _ = data_module.get_loaders()

    # 4ï¸âƒ£ æ„å»ºæ¨¡å‹
    model = build_model(config.get("model", {})).to(device)
    print("âœ… æ¨¡å‹å·²æ„å»ºå®Œæˆ")

    # 5ï¸âƒ£ å®šä¹‰æŸå¤±ä¸ä¼˜åŒ–å™¨
    criterion = torch.nn.SmoothL1Loss()
    optimizer = optim.Adam(
        model.parameters(),
        lr=config.get("optimizer", {}).get("lr", 1e-4),
        weight_decay=1e-5
    )
    scheduler = build_scheduler(optimizer, config)

    # 6ï¸âƒ£ å®éªŒæ–‡ä»¶å¤¹ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    exp_dir = f"results/exp_{timestamp}"
    os.makedirs(exp_dir, exist_ok=True)
    os.makedirs("checkpoints", exist_ok=True)

    # ä¿å­˜é…ç½®å‰¯æœ¬ä¸æ¨¡å‹ç»“æ„
    shutil.copy(config_path, os.path.join(exp_dir, "config_used.json"))
    with open(os.path.join(exp_dir, "model_summary.txt"), "w") as f:
        f.write(str(model))

    # 7ï¸âƒ£ è®­ç»ƒä¸»å¾ªç¯
    num_epochs = config.get("training", {}).get("n_epochs", 50)
    best_val_loss = float('inf')
    history = {"epoch": [], "train_loss": [], "val_loss": [], "lr": [], "val_mse_real": [], "val_mae_real": []}

    for epoch in range(1, num_epochs + 1):
        print(f"\n========== Epoch {epoch}/{num_epochs} ==========")

        # è®­ç»ƒï¼ˆtrain_epoch è¿”å› (epoch_loss, optional_metrics)ï¼‰
        train_loss, _ = train_epoch(epoch, train_loader, model, criterion, optimizer, device)

        # éªŒè¯ï¼ˆval_epoch è¿”å› (epoch_loss, (mse_real, mae_real))ï¼‰
        val_loss, (val_mse_real, val_mae_real) = val_epoch(epoch, val_loader, model, criterion, device)

        # æ›´æ–°å­¦ä¹ ç‡ï¼ˆå¦‚æœä½¿ç”¨ LambdaLR ç­‰æŒ‰ epoch è°ƒåº¦ï¼‰
        if scheduler is not None:
            scheduler.step()

        lr = optimizer.param_groups[0]['lr']
        print(f"ğŸ“‰ å½“å‰å­¦ä¹ ç‡: {lr:.8f}")

        # æ‰“å°æœ¬ epoch æŒ‡æ ‡ï¼ˆtrain_loss ä¸ val_loss ä½¿ç”¨ SmoothL1Lossï¼Œmse/mae æ˜¯åå½’ä¸€åŒ–åçš„è¯„ä¼°æŒ‡æ ‡ï¼‰
        print(f"ğŸ“ Epoch {epoch}: Train={train_loss:.6f}, Val={val_loss:.6f}, MSE_real={val_mse_real:.2f}, MAE_real={val_mae_real:.2f}")

        # è®°å½•æ—¥å¿—
        history["epoch"].append(epoch)
        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["lr"].append(lr)
        history["val_mse_real"].append(val_mse_real)
        history["val_mae_real"].append(val_mae_real)

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_path = f"checkpoints/best_model_epoch_{epoch}.pth"
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ’¾ æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜: {best_model_path}")

        # å¯è§†åŒ–ï¼ˆæ¯ 10 ä¸ª epoch æˆ–æœ€åä¸€ä¸ª epochï¼‰
        if epoch % 10 == 0 or epoch == num_epochs:
            plot_predictions(model, val_loader, device, epoch, label_mean, label_std, save_dir=exp_dir)

    print("âœ… è®­ç»ƒå®Œæˆï¼")

    # 8ï¸âƒ£ ä¿å­˜æ—¥å¿—ä¸æ›²çº¿
    df = pd.DataFrame(history)
    csv_path = os.path.join(exp_dir, "training_log.csv")
    df.to_csv(csv_path, index=False)
    print(f"ğŸ§¾ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜åˆ°: {csv_path}")

    # Loss æ›²çº¿
    plt.figure(figsize=(8, 6))
    plt.plot(df["epoch"], df["train_loss"], label='Train Loss', marker='o')
    plt.plot(df["epoch"], df["val_loss"], label='Val Loss', marker='s')
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(exp_dir, "loss_curve.png"))
    plt.close()

    # å­¦ä¹ ç‡æ›²çº¿
    plt.figure(figsize=(8, 5))
    plt.plot(df["epoch"], df["lr"], label='Learning Rate', color='purple')
    plt.xlabel("Epoch")
    plt.ylabel("LR")
    plt.title("Learning Rate Schedule")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(exp_dir, "lr_curve.png"))
    plt.close()

    print(f"ğŸ“Š æ‰€æœ‰æ›²çº¿ä¸æ—¥å¿—å‡å·²ä¿å­˜è‡³: {exp_dir}")



if __name__ == "__main__":
    main()
