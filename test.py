#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import sys
import json
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm
import datetime

from models.model_builder import build_model
from loader.ParticleDataset import ParticleDataset


# ===============================================================
# ğŸ”§ åŸºæœ¬é…ç½®
# ===============================================================
CONFIG_PATH = "data/particle_config/particle_config.json"
CHECKPOINT_DIR = "checkpoints"
RESULTS_BASE = "results"
os.makedirs(RESULTS_BASE, exist_ok=True)

# å®æ—¶è¾“å‡º
print = lambda *args, **kwargs: (__import__("builtins").print(*args, **kwargs), sys.stdout.flush())


# ===============================================================
# ğŸ§  è‡ªåŠ¨åŠ è½½æœ€æ–° checkpoint
# ===============================================================
def load_latest_checkpoint(checkpoint_dir):
    ckpts = [f for f in os.listdir(checkpoint_dir) if f.endswith(".pth")]
    if not ckpts:
        raise FileNotFoundError(f"æœªåœ¨ {checkpoint_dir} ä¸­æ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶ (.pth)")
    ckpts = sorted(ckpts, key=lambda x: int(''.join(filter(str.isdigit, x)) or 0))
    latest = os.path.join(checkpoint_dir, ckpts[-1])
    print(f"âœ… å·²åŠ è½½æœ€æ–°æƒé‡: {latest}")
    return latest


# ===============================================================
# ğŸ§® ä¸»æ¨ç†å‡½æ•°
# ===============================================================
def main():
    # 1ï¸âƒ£ è¯»å–é…ç½®
    print("åŠ è½½é…ç½®ä¸­...")
    with open(CONFIG_PATH, "r") as f:
        config = json.load(f)

    # 2ï¸âƒ£ æå–å½’ä¸€åŒ–å‚æ•°ï¼ˆä» normalization_params.jsonï¼‰
    norm_path = "data/norm_params/normalization_params.json"
    if not os.path.exists(norm_path):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°å½’ä¸€åŒ–å‚æ•°æ–‡ä»¶: {norm_path}")

    with open(norm_path, "r") as f:
        norm_params = json.load(f)

    # è½¬æˆ numpy æ•°ç»„
    input_mean = np.array(norm_params.get("input_mean", [0]))
    input_std = np.array(norm_params.get("input_std", [1]))
    label_mean = np.array(norm_params.get("label_mean", [0]))
    label_std = np.array(norm_params.get("label_std", [1]))

    # âœ… æ£€æŸ¥å½¢çŠ¶ï¼ˆinput 4é€šé“ï¼‰
    if input_mean.size != 4 or input_std.size != 4:
        raise ValueError(f"âŒ input_mean/std å½¢çŠ¶é”™è¯¯: mean={input_mean.shape}, std={input_std.shape}ï¼Œåº”ä¸ºé•¿åº¦4")

    print(f"âœ… å·²åŠ è½½å½’ä¸€åŒ–å‚æ•° from {norm_path}")
    print(f"   input_mean: {input_mean}")
    print(f"   input_std : {input_std}")
    print(f"   label_mean shape: {label_mean.shape}, label_std shape: {label_std.shape}")

    # 3ï¸âƒ£ è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")

    # 4ï¸âƒ£ åŠ è½½æµ‹è¯•æ•°æ®
    dataset_cfg = config.get("dataset", {})
    test_files_cfg = config.get("test_filenames", [])
    if len(test_files_cfg) == 0:
        raise ValueError("âš ï¸ é…ç½®æ–‡ä»¶ä¸­ test_filenames ä¸ºç©º")

    test_dataset = ParticleDataset(
        filenames=test_files_cfg,
        transform=None,
        normalize_input=True,
        normalize_label=True,
        input_mean=input_mean,
        input_std=input_std,
        label_mean=label_mean,
        label_std=label_std
    )

    from torch.utils.data import DataLoader
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)
    print(f"âœ… æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")

    # 5ï¸âƒ£ æ„å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    model = build_model(config["model"]).to(device)
    ckpt_path = load_latest_checkpoint(CHECKPOINT_DIR)
    model.load_state_dict(torch.load(ckpt_path, map_location=device))
    model.eval()

    criterion = nn.SmoothL1Loss()
    total_loss = 0.0
    preds_list, labels_list, filenames = [], [], []

    # 6ï¸âƒ£ è¾“å‡ºè·¯å¾„
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    exp_dir = os.path.join(RESULTS_BASE, f"exp_{timestamp}_test")
    os.makedirs(exp_dir, exist_ok=True)

    # 7ï¸âƒ£ å¼€å§‹æ¨ç†
    print("ğŸš€ å¼€å§‹æ¨ç†...")
    with torch.no_grad():
        for batch_idx, batch in enumerate(tqdm(test_loader, desc="Testing", dynamic_ncols=True)):
            x = batch["image"].to(device)
            y = batch["label"].to(device)
            fname = batch["filename"][0]

            preds = model(x)
            preds = preds.view(preds.size(0), -1)
            y = y.view(y.size(0), -1)

            loss = criterion(preds, y)
            total_loss += loss.item()

            preds_np = preds.cpu().numpy().squeeze()
            labels_np = y.cpu().numpy().squeeze()

            # åå½’ä¸€åŒ–
            preds_np = preds_np * label_std + label_mean
            labels_np = labels_np * label_std + label_mean

            preds_list.append(preds_np)
            labels_list.append(labels_np)
            filenames.append(fname)

            # å‰å‡ ä¸ªæ ·æœ¬æ‰“å°
            if batch_idx < 3:
                nprint = min(10, len(preds_np))
                print(f"\næ ·æœ¬ {fname} (å‰{nprint}ä¸ªç‚¹, å·²åå½’ä¸€åŒ–):")
                for i in range(nprint):
                    print(f"  pred[{i:03d}]={preds_np[i]:.4f} | label[{i:03d}]={labels_np[i]:.4f}")

    # 8ï¸âƒ£ ç»“æœç»Ÿè®¡
    preds_all = np.stack(preds_list, axis=0)
    labels_all = np.stack(labels_list, axis=0)
    avg_loss = total_loss / len(test_loader)

    # è®¡ç®—çœŸå®è¯¯å·®æŒ‡æ ‡
    mse_real = np.mean((preds_all - labels_all) ** 2)
    mae_real = np.mean(np.abs(preds_all - labels_all))
    ss_res = np.sum((labels_all - preds_all) ** 2)
    ss_tot = np.sum((labels_all - np.mean(labels_all)) ** 2)
    r2_score = 1 - ss_res / ss_tot

    print(f"\nâœ… æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“Š å¹³å‡ SmoothL1Loss(å½’ä¸€åŒ–åŸŸ) = {avg_loss:.6f}")
    print(f"ğŸ“ çœŸå®è¯¯å·®: MSE={mse_real:.3f} | MAE={mae_real:.3f} | RÂ²={r2_score:.4f}")

    # 9ï¸âƒ£ ä¿å­˜ç»“æœ
    np.save(os.path.join(exp_dir, "preds_all.npy"), preds_all)
    np.save(os.path.join(exp_dir, "labels_all.npy"), labels_all)

    # 9ï¸âƒ£ ä¿å­˜ç»“æœ
    preds_all = np.stack(preds_list, axis=0)
    labels_all = np.stack(labels_list, axis=0)
    avg_loss = total_loss / len(test_loader)

    # è®¡ç®—çœŸå®è¯¯å·®æŒ‡æ ‡
    mse_real = np.mean((preds_all - labels_all) ** 2)
    mae_real = np.mean(np.abs(preds_all - labels_all))
    ss_res = np.sum((labels_all - preds_all) ** 2)
    ss_tot = np.sum((labels_all - np.mean(labels_all)) ** 2)
    r2_score = 1 - ss_res / ss_tot

    print(f"\nâœ… æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“Š å¹³å‡ SmoothL1Loss(å½’ä¸€åŒ–åŸŸ) = {avg_loss:.6f}")
    print(f"ğŸ“ çœŸå®è¯¯å·®: MSE={mse_real:.3f} | MAE={mae_real:.3f} | RÂ²={r2_score:.4f}")

    # =========================================================
    # âœ… ç”Ÿæˆäº¤é”™åˆ—æ ¼å¼çš„ CSV: filename, pred_0, label_0, pred_1, label_1, ...
    # =========================================================
    N, D = preds_all.shape
    cols = ["filename"]
    for i in range(D):
        cols += [f"pred_{i}", f"label_{i}"]

    rows = []
    for i in range(N):
        row = [filenames[i]]
        for j in range(D):
            row += [preds_all[i, j], labels_all[i, j]]
        rows.append(row)

    df = pd.DataFrame(rows, columns=cols)
    csv_path = os.path.join(exp_dir, "test_results.csv")
    df.to_csv(csv_path, index=False)
    print(f"âœ… å·²ä¿å­˜äº¤é”™æ ¼å¼ CSV -> {csv_path}")


    # è¯¯å·®æ‘˜è¦
    metrics_path = os.path.join(exp_dir, "metrics_summary.txt")
    with open(metrics_path, "w") as f:
        f.write(f"Average SmoothL1Loss (normalized): {avg_loss:.6f}\n")
        f.write(f"MSE (real): {mse_real:.6f}\n")
        f.write(f"MAE (real): {mae_real:.6f}\n")
        f.write(f"RÂ² (real): {r2_score:.6f}\n")
    print(f"âœ… è¯¯å·®æ‘˜è¦ä¿å­˜è‡³: {metrics_path}")

    # 10ï¸âƒ£ ç»˜å›¾ä¿å­˜
    plt.figure(figsize=(14, 5))
    plt.plot(preds_all.flatten(), label="Prediction", linewidth=0.8)
    plt.plot(labels_all.flatten(), label="Ground Truth", linewidth=0.8)
    plt.title(f"Prediction vs Ground Truth (MSE={mse_real:.3f}, MAE={mae_real:.3f}, RÂ²={r2_score:.3f})")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(os.path.join(exp_dir, "test_predictions_curve.png"), dpi=300)
    plt.close()

    # æ•£ç‚¹å¯¹æ¯”å›¾
    plt.figure(figsize=(6, 6))
    plt.scatter(labels_all.flatten(), preds_all.flatten(), s=5, alpha=0.5)
    plt.xlabel("True Values")
    plt.ylabel("Predictions")
    plt.title("Predicted vs True (after denormalization)")
    plt.grid(True, linestyle="--", alpha=0.4)
    plt.tight_layout()
    plt.savefig(os.path.join(exp_dir, "scatter_pred_vs_true.png"), dpi=300)
    plt.close()

    print(f"ğŸ¨ æ‰€æœ‰å›¾åƒä¸ç»“æœå·²ä¿å­˜åˆ°: {exp_dir}")


if __name__ == "__main__":
    main()
