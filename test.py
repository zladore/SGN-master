#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_infer.py
é€‚é…äº main.py è‡ªåŠ¨æ¨ç†è°ƒç”¨ã€‚
æ”¯æŒï¼š
 - è‡ªåŠ¨é€‰æ‹©æœ€æ–°æˆ–æŒ‡å®š checkpoint
 - ä½¿ç”¨å›ºå®šå½’ä¸€åŒ–å‚æ•°è·¯å¾„
 - è¾“å‡ºå®Œæ•´æŒ‡æ ‡ä¸å¯è§†åŒ–
"""

import os
import sys
import json
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm
import datetime

from models.model_builder import build_model
from loader.ParticleDataset import ParticleDataset


# ===============================================================
# ğŸ§­ é€šç”¨é…ç½®
# ===============================================================
CONFIG_PATH = "data/particle_config/particle_config.json"
NORM_PARAM_PATH = "data/norm_params/normalization_params.json"
CHECKPOINT_DIR = "checkpoints"
RESULTS_BASE = "results"
os.makedirs(RESULTS_BASE, exist_ok=True)


# ===============================================================
# ğŸ” è‡ªåŠ¨åŠ è½½ checkpoint
# ===============================================================
def get_checkpoint_path(checkpoint_dir, specified_ckpt=None):
    """
    è‹¥æŒ‡å®šè·¯å¾„å­˜åœ¨ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›
    è‹¥ä¸å­˜åœ¨ï¼Œåˆ™å›é€€åˆ°ç›®å½•ä¸­æœ€æ–°çš„ checkpointã€‚
    """
    if specified_ckpt and os.path.exists(specified_ckpt):
        print(f"âœ… ä½¿ç”¨æŒ‡å®šæ¨¡å‹æƒé‡: {specified_ckpt}")
        return specified_ckpt

    ckpts = [f for f in os.listdir(checkpoint_dir) if f.endswith(".pth")]
    if not ckpts:
        raise FileNotFoundError(f"âŒ æœªåœ¨ {checkpoint_dir} ä¸­æ‰¾åˆ°ä»»ä½• .pth æ–‡ä»¶")

    ckpts = sorted(ckpts, key=lambda x: os.path.getmtime(os.path.join(checkpoint_dir, x)))
    latest = os.path.join(checkpoint_dir, ckpts[-1])
    print(f"âš ï¸ æŒ‡å®šçš„æƒé‡æœªæ‰¾åˆ°ï¼Œå·²å›é€€åˆ°æœ€æ–°æƒé‡: {latest}")
    return latest


# ===============================================================
# ğŸ§® æ¨ç†å‡½æ•°ï¼ˆå¯ä» main.py è°ƒç”¨ï¼‰
# ===============================================================
def run_inference(checkpoint_path=None, tag="auto_test"):
    """
    å¯è¢« main.py è°ƒç”¨çš„æ¨ç†å‡½æ•°ã€‚
    Args:
        checkpoint_path (str, optional): æŒ‡å®š checkpoint è·¯å¾„ã€‚
        tag (str): è¾“å‡ºæ–‡ä»¶å¤¹æ ‡è¯†åã€‚
    """
    # ---------------------------------------------------------------
    # 1ï¸âƒ£ åŠ è½½é…ç½®
    # ---------------------------------------------------------------
    print("ğŸ“˜ åŠ è½½é…ç½®ä¸å½’ä¸€åŒ–å‚æ•°...")
    with open(CONFIG_PATH, "r") as f:
        config = json.load(f)

    # å½’ä¸€åŒ–å‚æ•°
    with open(NORM_PARAM_PATH, "r") as f:
        norm_params = json.load(f)

    input_mean = np.array(norm_params.get("input_mean", [0]))
    input_std = np.array(norm_params.get("input_std", [1]))
    label_mean = np.array(norm_params.get("label_mean", [0]))
    label_std = np.array(norm_params.get("label_std", [1]))

    if input_mean.size != 4 or input_std.size != 4:
        raise ValueError(f"âŒ input_mean/std å½¢çŠ¶é”™è¯¯ï¼Œåº”ä¸ºé•¿åº¦3")

    # ---------------------------------------------------------------
    # 2ï¸âƒ£ è®¾ç½®è®¾å¤‡ & åŠ è½½æ¨¡å‹
    # ---------------------------------------------------------------
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = build_model(config["model"]).to(device)

    ckpt_path = get_checkpoint_path(CHECKPOINT_DIR, checkpoint_path)
    model.load_state_dict(torch.load(ckpt_path, map_location=device))
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {ckpt_path}")

    # ---------------------------------------------------------------
    # 3ï¸âƒ£ æ•°æ®é›†å‡†å¤‡
    # ---------------------------------------------------------------
    test_files_cfg = config.get("test_filenames", [])
    if not test_files_cfg:
        raise ValueError("âš ï¸ é…ç½®æ–‡ä»¶ä¸­ test_filenames ä¸ºç©ºï¼")

    test_dataset = ParticleDataset(
        filenames=test_files_cfg,
        transform=None,
        normalize_input=True,
        normalize_label=True,
        input_mean=input_mean,
        input_std=input_std,
        label_mean=label_mean,
        label_std=label_std
    )

    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)
    print(f"âœ… æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")

    # ---------------------------------------------------------------
    # 4ï¸âƒ£ æ¨ç†å¾ªç¯
    # ---------------------------------------------------------------
    criterion = nn.SmoothL1Loss()
    total_loss = 0.0
    preds_list, labels_list, filenames = [], [], []

    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    exp_dir = os.path.join(RESULTS_BASE, f"{tag}_{timestamp}")
    os.makedirs(exp_dir, exist_ok=True)

    print("ğŸš€ å¼€å§‹æ¨ç†...")
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing", dynamic_ncols=True):
            x = batch["image"].to(device)
            y = batch["label"].to(device)
            fname = batch["filename"][0]

            preds = model(x).view(x.size(0), -1)
            y = y.view(y.size(0), -1)

            loss = criterion(preds, y)
            total_loss += loss.item()

            preds_np = preds.cpu().numpy().squeeze()
            labels_np = y.cpu().numpy().squeeze()

            preds_np = preds_np * label_std + label_mean
            labels_np = labels_np * label_std + label_mean

            preds_list.append(preds_np)
            labels_list.append(labels_np)
            filenames.append(fname)

    # ---------------------------------------------------------------
    # 5ï¸âƒ£ ç»“æœè®¡ç®—ä¸ä¿å­˜
    # ---------------------------------------------------------------
    preds_all = np.stack(preds_list)
    labels_all = np.stack(labels_list)

    avg_loss = total_loss / len(test_loader)
    mse_real = np.mean((preds_all - labels_all) ** 2)
    mae_real = np.mean(np.abs(preds_all - labels_all))
    ss_res = np.sum((labels_all - preds_all) ** 2)
    ss_tot = np.sum((labels_all - np.mean(labels_all)) ** 2)
    r2_score = 1 - ss_res / ss_tot

    print(f"\nâœ… æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“Š SmoothL1Loss(å½’ä¸€åŒ–åŸŸ)={avg_loss:.6f}")
    print(f"ğŸ“ MSE={mse_real:.3f} | MAE={mae_real:.3f} | RÂ²={r2_score:.4f}")

    # ä¿å­˜ CSVï¼ˆäº¤é”™æ ¼å¼ï¼‰
    cols = ["filename"] + [f"pred_{i},label_{i}" for i in range(preds_all.shape[1])]
    df_rows = []
    for i, fname in enumerate(filenames):
        row = [fname]
        for j in range(preds_all.shape[1]):
            row += [preds_all[i, j], labels_all[i, j]]
        df_rows.append(row)

    df = pd.DataFrame(df_rows, columns=["filename"] + sum([[f"pred_{i}", f"label_{i}"] for i in range(preds_all.shape[1])], []))
    csv_path = os.path.join(exp_dir, "test_results.csv")
    df.to_csv(csv_path, index=False)
    print(f"âœ… CSV å·²ä¿å­˜ -> {csv_path}")

    # ä¿å­˜è¯¯å·®æ‘˜è¦
    with open(os.path.join(exp_dir, "metrics_summary.txt"), "w") as f:
        f.write(f"Average SmoothL1Loss: {avg_loss:.6f}\n")
        f.write(f"MSE: {mse_real:.6f}\n")
        f.write(f"MAE: {mae_real:.6f}\n")
        f.write(f"RÂ²: {r2_score:.6f}\n")

    # ç»˜å›¾
    plt.figure(figsize=(14, 5))
    plt.plot(preds_all.flatten(), label="Pred")
    plt.plot(labels_all.flatten(), label="True")
    plt.legend(); plt.grid(True, linestyle="--", alpha=0.4)
    plt.title(f"MSE={mse_real:.3f}, MAE={mae_real:.3f}, RÂ²={r2_score:.3f}")
    plt.tight_layout()
    plt.savefig(os.path.join(exp_dir, "curve.png"), dpi=300)
    plt.close()

    plt.figure(figsize=(6, 6))
    plt.scatter(labels_all.flatten(), preds_all.flatten(), s=5, alpha=0.5)
    plt.xlabel("True"); plt.ylabel("Pred"); plt.grid(True, linestyle="--", alpha=0.4)
    plt.title("Pred vs True")
    plt.tight_layout()
    plt.savefig(os.path.join(exp_dir, "scatter.png"), dpi=300)
    plt.close()

    print(f"ğŸ¨ æ‰€æœ‰å›¾åƒä¸ç»“æœå·²ä¿å­˜è‡³ {exp_dir}")

    return {
        "exp_dir": exp_dir,
        "ckpt": ckpt_path,
        "avg_loss": avg_loss,
        "mse": mse_real,
        "mae": mae_real,
        "r2": r2_score
    }


# ===============================================================
# CLI å¯åŠ¨
# ===============================================================
if __name__ == "__main__":
    run_inference()
